---
hide:
  - navigation
  - toc
---

<p align="center">
  <img src="https://github.com/Silleellie/LaikaLLM/assets/26851363/a43ed66b-f420-40e3-b261-9cfa690648fa" alt="drawing" width="50%"/>
</p>

# LaikaLLM

LaikaLLM is a software, for researchers, that helps in setting up a repeatable, reproducible, 
replicable protocol for **training** and **evaluating** <ins>multitask</ins> LLM for recommendation!

*Features*:

- Two different model family implemented at the moment of writing (***T5*** and ***GPT2***)
- Fully vectorized *Ranking* (`NDCG`, `MAP`, `HitRate`, ...) and *Error* (`RMSE`, `MAE`) metrics
- Fully integrated with **WandB** monitoring service
- Full use of *transformers* and *datasets* libraries
- Easy to use (via `.yaml` configuration or *Python api*)
- Fast (Intended to be used for *consumer gpus*)
- Fully modular and easily extensible!

The **goal** of LaikaLLM is to be the starting point, a *hub*, for all developers which want to evaluate the capability 
of LLM models in the **recommender system** domain with a *keen eye* on **devops** best practices!

Want a glimpse of LaikaLLM? This is an example configuration which runs the whole experiment pipeline, starting
from **data pre-processing**, to **evaluation**:

```yaml
exp_name: to_the_moon
device: cuda:0
random_seed: 42

data:
  AmazonDataset:
    dataset_name: toys

model:
  T5Rec:
    name_or_path: "google/flan-t5-base"
  n_epochs: 10
  train_batch_size: 32
  train_tasks:
    - SequentialSideInfoTask
    - RatingPredictionTask

eval:
  eval_batch_size: 16
  eval_tasks:
    SequentialSideInfoTask:
      - hit@1
      - hit@5
      - map@5
    RatingPredictionTask:
      - rmse
```

The whole pipeline can then be executed by simply invoking `python laikaLLM.py -c config.yml`!

## Motivation

The adoption of LLM in the recommender system domain is a *new* research area, thus it's **difficult** to 
find **pre-made** and **well-built** software designed *specifically* for LLM.

With *LaikaLLM* the idea is to fill that gap, or at least "start the conversation" about the importance
of developing *accountable* experiment pipelines

## Credits

A heartfelt "thank you" to [P5](https://github.com/jeykigung/P5) authors which, with their work, inspired the idea
of this repository and for making available a 
[preprocessed version](https://drive.google.com/file/d/1qGxgmx7G_WB7JE4Cn_bEcZ_o_NAJLE3G/view?usp=sharing) of the 
[Amazon Dataset](https://huggingface.co/datasets/amazon_us_reviews) which in this project I've used as starting point 
for further manipulation.

> Yes, the cute logo is A.I. generated. So thank you DALL-E 3! 

Project Organization
------------
    â”œâ”€â”€ ğŸ“ data                          <- Directory containing all data generated/used
    â”‚   â”œâ”€â”€ ğŸ“ processed                     <- The final, canonical data sets used for training/validation/evaluation
    â”‚   â””â”€â”€ ğŸ“ raw                           <- The original, immutable data dump
    â”‚
    â”œâ”€â”€ ğŸ“ models                        <- Directory where trained and serialized models will be stored
    â”‚
    â”œâ”€â”€ ğŸ“ reports                       <- Where metrics will be stored after performing the evaluation phase
    â”‚   â””â”€â”€ ğŸ“ metrics                          
    â”‚
    â”œâ”€â”€ ğŸ“ src                           <- Source code of the project
    â”‚   â”œâ”€â”€ ğŸ“ data                          <- All scripts related to datasets and tasks
    â”‚   â”‚   â”œâ”€â”€ ğŸ“ datasets                  <- All datasets implemented
    â”‚   â”‚   â”œâ”€â”€ ğŸ“ tasks                     <- All tasks implemented
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ abstract_dataset.py       <- The interface that all datasets should implement
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ abstract_task.py          <- The interface that all tasks should implement
    â”‚   â”‚   â””â”€â”€ ğŸ“„ main.py                   <- Script used to perform the data phase when using LaikaLLM via .yaml
    â”‚   â”‚
    â”‚   â”œâ”€â”€ ğŸ“ evaluate                  <- Scripts to evaluate the trained models
    â”‚   â”‚   â”œâ”€â”€ ğŸ“ metrics                   <- Scripts containing different metrics to evaluate the predictions generated
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ abstract_metric.py        <- The interface that all metrics should implement
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ evaluator.py              <- Script containing the Evaluator class used for performing the eval phase
    â”‚   â”‚   â””â”€â”€ ğŸ“„ main.py                   <- Script used to perform the eval phase when using LaikaLLM via .yaml
    â”‚   â”‚
    â”‚   â”œâ”€â”€ ğŸ“ model                     <- Scripts to define and train models
    â”‚   â”‚   â”œâ”€â”€ ğŸ“ models                    <- Scripts containing all the models implemented
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ abstract_model.py         <- The interface that all models should implement
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ main.py                   <- Script used to perform the eval phase when using LaikaLLM via .yaml
    â”‚   â”‚   â””â”€â”€ ğŸ“„ trainer.py                <- Script containing the Trainer class used for performing the train phase
    â”‚   â”‚
    â”‚   â”œâ”€â”€ ğŸ“„ __init__.py               <- Makes src a Python module
    â”‚   â”œâ”€â”€ ğŸ“„ utils.py                  <- Contains utils function for the project
    â”‚   â””â”€â”€ ğŸ“„ yml_parse.py              <- Script responsible for coordinating the parsing of the .yaml file
    â”‚
    â”œâ”€â”€ ğŸ“„ LICENSE                       <- MIT License
    â”œâ”€â”€ ğŸ“„ laikaLLM.py                   <- Script to invoke via command line to use LaikaLLM via .yaml
    â”œâ”€â”€ ğŸ“„ params.yml                    <- The example .yaml config for starting using LaikaLLM
    â”œâ”€â”€ ğŸ“„ README.md                     <- The top-level README for developers using this project
    â””â”€â”€ ğŸ“„ requirements.txt              <- The requirements file for reproducing the environment (src package)

--------

<p><small>Project based on the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>
